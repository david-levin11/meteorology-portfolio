{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-levin11/meteorology-portfolio/blob/main/Representative_Clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iYyzL_9EAm7"
      },
      "source": [
        "**ECMWF Representative Member Clustering**\n",
        "<br/>\n",
        "Description--It's often a frustration to view the cluster analysis and wish that there was some sort of deterministic model that was centered on each cluster in order to view how that particular scenario might play out.  This notebook attempts to address that problem by running k-means clustering on 500mb heights from the ECMWF Ensemble and then selecting the member that is closest in the cluster phase space to each cluster centroid.  The user can then select the cluster they want to view and the corresponding field and the notebook will plot the selected representative member during the cluster time frame.  \n",
        "\n",
        "\n",
        "Questions?  Concerns?  Additions?  Contact me and let me know!\n",
        "\n",
        "- David Levin, Arctic Testbed & Proving Ground, Anchorage Alaska"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t56SexSlUELy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNRHFuNmC-2K"
      },
      "source": [
        "##**1 - Install and Import Packages**\n",
        "This will take about a minute to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJaogqYCNB-Q",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "!pip install ecmwf-opendata eccodes==2.38.3 cfgrib xarray scikit-learn cartopy\n",
        "import warnings\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from ecmwf.opendata import Client\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.ndimage as ndimage\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import cartopy.io.shapereader as shpreader\n",
        "import matplotlib as mpl\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "from matplotlib.patches import Patch\n",
        "from matplotlib.colors import Normalize, LinearSegmentedColormap, BoundaryNorm, TwoSlopeNorm, to_hex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 - Set Options & Download Data**"
      ],
      "metadata": {
        "id": "o__Uh-rHwlW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def download_ecmwf_ens(\n",
        "    param: str,\n",
        "    init_time: datetime,\n",
        "    steps,\n",
        "    *,\n",
        "    level_type: str = \"sfc\",          # \"sfc\" or \"pl\"\n",
        "    levels=None,                      # e.g., [500] or [1000,850,700] for levtype=\"pl\"\n",
        "    members=\"all\",                    # \"all\", \"control\", \"mean\", \"stdev\", or list of ints (e.g., [1,3,5])\n",
        "    target_dir=\".\",\n",
        "    source: str = \"aws\"             # \"ecmwf\", \"aws\", or \"azure\"\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Download ECMWF ENS data (Open Data) for a given init, variable, and steps.\n",
        "\n",
        "    Examples:\n",
        "      - Surface:   param=\"tp\", level_type=\"sfc\"\n",
        "      - Pressure:  param=\"z\",  level_type=\"pl\", levels=[500]\n",
        "      - Members:   members=\"all\" (pf), \"control\" (cf), \"mean\" (em), \"stdev\" (es), or [1,2,3]\n",
        "      - Steps:     integer, list[int], or \"0/6/240\" (MARS-style)\n",
        "    \"\"\"\n",
        "    # Normalize inputs\n",
        "    date_str = init_time.strftime(\"%Y-%m-%d\")\n",
        "    hour = int(init_time.strftime(\"%H\"))\n",
        "\n",
        "    # steps can be int, list, or MARS-style string\n",
        "    if isinstance(steps, int):\n",
        "        step_val = steps\n",
        "    elif isinstance(steps, (list, tuple)):\n",
        "        step_val = \"/\".join(str(s) for s in steps)\n",
        "    else:\n",
        "        # assume caller passed a MARS-style range like \"0/6/240\" or \"0/to/240/by/6\"\n",
        "        step_val = str(steps)\n",
        "\n",
        "    # Map members choice to ECMWF type/number\n",
        "    mtype = \"pf\"  # perturbed members by default\n",
        "    number_kw = {}\n",
        "    if isinstance(members, str):\n",
        "        m = members.lower()\n",
        "        if m == \"control\":\n",
        "            mtype = \"cf\"\n",
        "        elif m == \"mean\":\n",
        "            mtype = \"em\"\n",
        "        elif m == \"stdev\":\n",
        "            mtype = \"es\"\n",
        "        elif m == \"all\":\n",
        "            pass  # pf + no \"number\" downloads all perturbed members\n",
        "        else:\n",
        "            raise ValueError(\"members must be 'all', 'control', 'mean', 'stdev', or a list of ints.\")\n",
        "    else:\n",
        "        # explicit list of member numbers\n",
        "        mtype = \"pf\"\n",
        "        nums = list(members)\n",
        "        if not nums:\n",
        "            raise ValueError(\"members list is empty.\")\n",
        "        number_kw = {\"number\": nums}\n",
        "\n",
        "    # Level keywords\n",
        "    level_kw = {}\n",
        "    levtype = level_type.lower()\n",
        "    if levtype == \"pl\":\n",
        "        if not levels:\n",
        "            raise ValueError(\"Pressure-level request requires 'levels' (e.g., [500] or [1000,850,700]).\")\n",
        "        level_kw = {\"levtype\": \"pl\", \"levelist\": \"/\".join(str(l) for l in levels)}\n",
        "        level_label = f\"pl_{'-'.join(str(l) for l in levels)}\"\n",
        "    elif levtype == \"sfc\":\n",
        "        level_kw = {\"levtype\": \"sfc\"}\n",
        "        level_label = \"sfc\"\n",
        "    else:\n",
        "        raise ValueError(\"level_type must be 'sfc' or 'pl'.\")\n",
        "\n",
        "    # Build output filename\n",
        "    if isinstance(param, list):\n",
        "      param_key = \"_\".join(param)\n",
        "    else:\n",
        "      param_key = param\n",
        "    steps_label = str(steps) if isinstance(steps, str) else step_val.replace(\"/\", \"-\")\n",
        "    member_label = members if isinstance(members, str) else f\"m{','.join(map(str, members))}\"\n",
        "    target_dir = Path(target_dir)\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    outfile = target_dir / f\"ecmwf_ens_{param_key}_{level_label}_{date_str.replace('-','')}{hour:02d}.grib2\"\n",
        "\n",
        "    # Create client and request\n",
        "    client = Client(source=source)\n",
        "    req = {\n",
        "        \"date\": date_str,\n",
        "        \"time\": hour,\n",
        "        \"stream\": \"enfo\",\n",
        "        \"type\": mtype,\n",
        "        \"param\": param,\n",
        "        \"step\": step_val,\n",
        "        **level_kw,\n",
        "        **number_kw,\n",
        "        \"target\": str(outfile),\n",
        "    }\n",
        "\n",
        "    # Retrieve\n",
        "    client.retrieve(**req)\n",
        "    return outfile\n",
        "\n",
        "#@markdown What is your model run initialization date?\n",
        "init_date = \"2025-08-21\" #@param {type:\"date\"}\n",
        "#@markdown What is your model run time\n",
        "init_time = 00 #@param [\"00\",  \"12\"] {type:\"raw\"}\n",
        "param = \"500mb Height\"\n",
        "param_dict = {\"Total Precipitation\": \"tp\", \"500mb Height\": \"gh\", \"Surface Pressure\": \"sp\"}\n",
        "#@markdown What time frame do you want to cluster on?\n",
        "timeframe = \"Day5\" #@param [\"Day5\", \"Day6\", \"Day7\", \"Day8\", \"Day9\", \"Day5-7\", \"Day6-8\", \"Day7-9\", \"Day5-8\", \"Day6-9\"]\n",
        "timeranges = {\n",
        "    \"Day5\": (120, 144),\n",
        "    \"Day6\": (144, 168),\n",
        "    \"Day7\": (168, 192),\n",
        "    \"Day8\": (192, 216),\n",
        "    \"Day9\": (216, 240),\n",
        "    \"Day5-7\": (120, 192),\n",
        "    \"Day6-8\": (144, 216),\n",
        "    \"Day7-9\": (168, 240),\n",
        "    \"Day5-8\": (120, 216),\n",
        "    \"Day6-9\": (144, 240),\n",
        "}\n",
        "tr = timeranges[timeframe]\n",
        "\n",
        "path = download_ecmwf_ens(\n",
        "    param=param_dict[param],\n",
        "    init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "    steps=list(range(timeranges[timeframe][0], timeranges[timeframe][1], 6)),\n",
        "    level_type=\"pl\",\n",
        "    levels=[500],\n",
        "    members=\"all\",\n",
        "    target_dir=\".\",\n",
        "    source=\"aws\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "mdXbkeRRU6Lk",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Perform Cluster Analysis & Plot EOF/Phase Space & Pick Representative Members**"
      ],
      "metadata": {
        "id": "ZkDYpSRT7aHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "def plot_mean_height_with_eof_shade_cartopy(\n",
        "    z_meters,            # xarray.DataArray [number, step, latitude, longitude] in meters\n",
        "    pca,                 # fitted PCA on stacked, √cosφ-weighted anomalies\n",
        "    window=(120,168),    # (start_hr, end_hr)\n",
        "    eof_indices=(0,1),   # which EOFs to draw\n",
        "    projection=None,     # a cartopy CRS; default is Lambert Conformal for Alaska\n",
        "    add_states=True,\n",
        "    add_borders=True,\n",
        "    coast_res=\"50m\",\n",
        "    n_contours=20,\n",
        "    cmap=\"RdBu_r\",\n",
        "    symmetric_shade=True,\n",
        "    scale=\"1sigma\"       # \"none\" or \"1sigma\"\n",
        "):\n",
        "    # coords\n",
        "    steps = z_meters.step.values\n",
        "    lat   = z_meters.latitude.values\n",
        "    lon   = z_meters.longitude.values\n",
        "    n_steps, n_lat, n_lon = len(steps), len(lat), len(lon)\n",
        "\n",
        "    # normalize lon to [-180, 180] if needed\n",
        "    if np.nanmax(lon) > 180:\n",
        "        lon = ((lon + 180) % 360) - 180\n",
        "        z_meters = z_meters.assign_coords(longitude=lon).sortby(\"longitude\")\n",
        "\n",
        "    steps_arr = np.asarray(steps)\n",
        "    if np.issubdtype(steps_arr.dtype, np.timedelta64):\n",
        "        step_hours = (steps_arr / np.timedelta64(1, \"h\")).astype(int)\n",
        "    else:\n",
        "        step_hours = steps_arr.astype(int)\n",
        "\n",
        "    s0, s1 = window\n",
        "    sel = (step_hours >= s0) & (step_hours <= s1)\n",
        "    if not np.any(sel):\n",
        "        raise ValueError(f\"No steps in {window}. Available: {step_hours.tolist()}\")\n",
        "\n",
        "    # mean height contours over window\n",
        "    z_mean = z_meters.sel(step=steps_arr[sel]).mean(dim=(\"number\",\"step\"))  # [lat, lon]\n",
        "\n",
        "    # weights for unweighting EOFs\n",
        "    wlat = np.sqrt(np.clip(np.cos(np.deg2rad(lat)), 1e-8, None))   # avoid 0 at poles\n",
        "    w2d  = wlat[:, None]\n",
        "\n",
        "    # lon/lat mesh\n",
        "    Lon, Lat = np.meshgrid(z_meters.longitude.values, z_meters.latitude.values)\n",
        "\n",
        "    # default projection for Alaska\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    figs = []\n",
        "    for k in eof_indices:\n",
        "        # component -> 3D -> window mean\n",
        "        comp = pca.components_[k].reshape(n_steps, n_lat, n_lon)\n",
        "        eof_mean_w = comp[sel].mean(axis=0)                      # weighted space\n",
        "\n",
        "        # 1-sigma scaling (still weighted)\n",
        "        if scale == \"1sigma\":\n",
        "            eof_mean_w = eof_mean_w * np.sqrt(pca.explained_variance_[k])\n",
        "\n",
        "        # unweight back to meters\n",
        "        eof_map = eof_mean_w / w2d\n",
        "\n",
        "        # symmetric color limits if requested\n",
        "        vlim = np.nanmax(np.abs(eof_map)) if symmetric_shade else None\n",
        "\n",
        "        # explained variance (%)\n",
        "        var_pct = 100.0 * float(pca.explained_variance_ratio_[k])\n",
        "\n",
        "        fig = plt.figure(figsize=(9, 5))\n",
        "        ax = plt.axes(projection=projection)\n",
        "\n",
        "        # set extent to your data bbox\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "\n",
        "        # shaded EOF anomaly\n",
        "        pm = ax.pcolormesh(\n",
        "            Lon, Lat, eof_map, shading=\"auto\", cmap=cmap,\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            **({} if not vlim else {\"vmin\": -vlim, \"vmax\": vlim})\n",
        "        )\n",
        "        cb = plt.colorbar(pm, ax=ax, orientation=\"vertical\", pad=0.02, label=\"EOF anomaly (m)\")\n",
        "\n",
        "        # mean height contours\n",
        "        cs = ax.contour(\n",
        "            Lon, Lat, z_mean, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "            transform=ccrs.PlateCarree()\n",
        "        )\n",
        "        ax.clabel(cs, fmt=\"%.0f\", fontsize=8)\n",
        "\n",
        "        # cartographic layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        if add_borders:\n",
        "            ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        if add_states:\n",
        "            ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "\n",
        "        # gridlines with labels\n",
        "        gl = ax.gridlines(draw_labels=True, linewidth=0.4, color=\"gray\", alpha=0.4, linestyle=\"--\")\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        ax.set_title(f\"Mean 500 mb (contours) + EOF{k+1} (shaded), {s0}–{s1} h — Var: {var_pct:.1f}%\")\n",
        "        plt.tight_layout()\n",
        "        figs.append(fig)\n",
        "\n",
        "    return tuple(figs)\n",
        "\n",
        "\n",
        "def plot_pc_phase_space(\n",
        "    pcs,\n",
        "    labels=None,\n",
        "    member_ids=None,\n",
        "    pca=None,                   # REQUIRED if standardize=True\n",
        "    cluster_centers=None,       # kmeans.cluster_centers_, optional\n",
        "    title=\"Ensemble Phase Space (PC1 vs PC2)\",\n",
        "    annotate=True,\n",
        "    standardize=True,           # <-- NEW: show scores in σ units\n",
        "    figsize=(7,7)\n",
        "):\n",
        "    pcs = np.asarray(pcs)\n",
        "    if pcs.shape[1] < 2:\n",
        "        raise ValueError(\"pcs must have at least 2 components.\")\n",
        "\n",
        "    # Standardize: divide each PC column by sqrt(eigenvalue)\n",
        "    if standardize:\n",
        "        if pca is None or not hasattr(pca, \"explained_variance_\"):\n",
        "            raise ValueError(\"pca with explained_variance_ is required when standardize=True.\")\n",
        "        sd = np.sqrt(pca.explained_variance_)[:pcs.shape[1]]\n",
        "        S = pcs / sd\n",
        "        if cluster_centers is not None:\n",
        "            centers_plot = np.asarray(cluster_centers) / sd\n",
        "        xlab = f\"PC1 (σ, {100*pca.explained_variance_ratio_[0]:.1f}%)\"\n",
        "        ylab = f\"PC2 (σ, {100*pca.explained_variance_ratio_[1]:.1f}%)\"\n",
        "    else:\n",
        "        S = pcs\n",
        "        centers_plot = np.asarray(cluster_centers) if cluster_centers is not None else None\n",
        "        if pca is not None and hasattr(pca, \"explained_variance_ratio_\"):\n",
        "            xlab = f\"PC1 ({100*pca.explained_variance_ratio_[0]:.1f}%)\"\n",
        "            ylab = f\"PC2 ({100*pca.explained_variance_ratio_[1]:.1f}%)\"\n",
        "        else:\n",
        "            xlab, ylab = \"PC1\", \"PC2\"\n",
        "\n",
        "    pc1, pc2 = S[:, 0], S[:, 1]\n",
        "    if labels is None:\n",
        "        labels = np.zeros(len(pc1), dtype=int)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    if member_ids is None:\n",
        "        member_ids = np.arange(len(pc1))\n",
        "    member_ids = np.asarray(member_ids)\n",
        "\n",
        "    uniq = np.unique(labels)\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, max(10, len(uniq))))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    for i, lab in enumerate(uniq):\n",
        "        sel = labels == lab\n",
        "        ax.scatter(pc1[sel], pc2[sel], s=40, alpha=0.8, label=f\"Cluster {lab} (n={sel.sum()})\", color=colors[i])\n",
        "\n",
        "    if annotate:\n",
        "        for x, y, mid in zip(pc1, pc2, member_ids):\n",
        "            ax.annotate(str(mid), (x, y), fontsize=8, xytext=(3, 3), textcoords=\"offset points\")\n",
        "\n",
        "    if cluster_centers is not None:\n",
        "        ax.scatter(centers_plot[:, 0], centers_plot[:, 1],\n",
        "                   marker=\"*\", s=200, edgecolor=\"k\", facecolor=\"none\", label=\"Centroids\")\n",
        "\n",
        "    ax.set_xlabel(xlab)\n",
        "    ax.set_ylabel(ylab)\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "    ax.legend(loc=\"best\", frameon=True)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def pick_cluster_representatives(\n",
        "    pcs,\n",
        "    labels,\n",
        "    member_ids,\n",
        "    *,\n",
        "    pca=None,                      # required if standardize=True\n",
        "    standardize=True,              # match your phase-space plot (σ units)\n",
        "    centers=None,                  # e.g., kmeans.cluster_centers_\n",
        "    n_components=2,                # use PC1..PCn\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns {cluster_label: representative_member_id} where the representative is\n",
        "    the member closest to that cluster's centroid in PC space.\n",
        "\n",
        "    pcs:         (n_members, n_pcs) PCA scores (from pca.transform or fit_transform)\n",
        "    labels:      (n_members,) cluster labels (ints)\n",
        "    member_ids:  (n_members,) identifiers (e.g., ENS numbers)\n",
        "    pca:         fitted PCA (needed if standardize=True)\n",
        "    centers:     (n_clusters, n_pcs) cluster centers in raw PC units (same as pcs)\n",
        "    \"\"\"\n",
        "    pcs = np.asarray(pcs)\n",
        "    labels = np.asarray(labels)\n",
        "    member_ids = np.asarray(member_ids)\n",
        "\n",
        "    if pcs.shape[1] < n_components:\n",
        "        raise ValueError(f\"pcs has only {pcs.shape[1]} components; need >= {n_components}\")\n",
        "\n",
        "    # Standardize to σ units if requested (divide each PC by sqrt(eigenvalue))\n",
        "    if standardize:\n",
        "        if pca is None or not hasattr(pca, \"explained_variance_\"):\n",
        "            raise ValueError(\"Provide fitted pca when standardize=True.\")\n",
        "        sd = np.sqrt(pca.explained_variance_)[:n_components]\n",
        "        S = pcs[:, :n_components] / sd\n",
        "        if centers is not None:\n",
        "            centers_plot = centers[:, :n_components] / sd\n",
        "        else:\n",
        "            centers_plot = None\n",
        "    else:\n",
        "        S = pcs[:, :n_components]\n",
        "        centers_plot = centers[:, :n_components] if centers is not None else None\n",
        "\n",
        "    reps = {}\n",
        "    uniq = np.unique(labels)\n",
        "    for c in uniq:\n",
        "        mask = labels == c\n",
        "        if not np.any(mask):\n",
        "            continue\n",
        "        Xc = S[mask]  # points in cluster c\n",
        "        mids = member_ids[mask]\n",
        "\n",
        "        # Use provided centers in the same (standardized) space if available; otherwise mean of cluster\n",
        "        if centers_plot is not None:\n",
        "            centroid = centers_plot[c]\n",
        "        else:\n",
        "            centroid = Xc.mean(axis=0)\n",
        "\n",
        "        # Euclidean distance to centroid\n",
        "        d2 = np.sum((Xc - centroid) ** 2, axis=1)\n",
        "        i_local = int(np.argmin(d2))\n",
        "        reps[int(c)] = int(mids[i_local])\n",
        "\n",
        "    return reps\n",
        "\n",
        "def plot_cluster_composites_500hpa(\n",
        "    z_meters,                 # xarray.DataArray [number, step, latitude, longitude] in meters\n",
        "    labels,                   # array-like of cluster labels per member (aligned to member_ids)\n",
        "    member_ids=None,          # array-like of z_meters.number matching labels; if None, assume same order as z_meters.number\n",
        "    window=(120, 168),        # (start_hr, end_hr) time window in hours\n",
        "    clusters_to_show=None,    # list/array of cluster labels to show; if None, first 4 sorted unique\n",
        "    projection=None,          # cartopy CRS; default Lambert Conformal for AK\n",
        "    coast_res=\"50m\",\n",
        "    cmap=\"RdBu_r\",\n",
        "    units=\"m\",                # \"m\" or \"dam\" for contour and anomaly units\n",
        "    n_contours=20,\n",
        "    symmetric_shade=True,\n",
        "    title=\"Cluster composites: mean 500 mb height (contours) + anomaly vs ensemble mean (shaded)\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Builds a 5-panel figure:\n",
        "      Panels 1-4: each cluster's mean height (contours) + anomaly vs ensemble mean (shaded)\n",
        "      Panel 5: total ensemble mean (contours only)\n",
        "    \"\"\"\n",
        "\n",
        "    # --- coords and basic prep\n",
        "    steps = z_meters.step.values\n",
        "    lat   = z_meters.latitude.values\n",
        "    lon   = z_meters.longitude.values\n",
        "\n",
        "    # normalize lon to [-180,180] if needed\n",
        "    if np.nanmax(lon) > 180:\n",
        "        lon = ((lon + 180) % 360) - 180\n",
        "        z_meters = z_meters.assign_coords(longitude=lon).sortby(\"longitude\")\n",
        "\n",
        "    # step mask\n",
        "    steps_arr = np.asarray(steps)\n",
        "    if np.issubdtype(steps_arr.dtype, np.timedelta64):\n",
        "        step_hours = (steps_arr / np.timedelta64(1, \"h\")).astype(int)\n",
        "    else:\n",
        "        step_hours = steps_arr.astype(int)\n",
        "    s0, s1 = window\n",
        "    sel = (step_hours >= s0) & (step_hours <= s1)\n",
        "    if not np.any(sel):\n",
        "        raise ValueError(f\"No steps in window {window}; available: {step_hours.tolist()}\")\n",
        "\n",
        "    # member id alignment\n",
        "    labels = np.asarray(labels)\n",
        "    if member_ids is None:\n",
        "        # assume labels align with z_meters.number order\n",
        "        member_ids = z_meters[\"number\"].values\n",
        "        if labels.shape[0] != member_ids.shape[0]:\n",
        "            raise ValueError(\"labels length does not match z_meters.number; provide member_ids explicitly.\")\n",
        "    else:\n",
        "        member_ids = np.asarray(member_ids)\n",
        "        if labels.shape[0] != member_ids.shape[0]:\n",
        "            raise ValueError(\"labels and member_ids must be same length.\")\n",
        "\n",
        "    # limit the data to members listed in member_ids (in case you dropped some before)\n",
        "    z_sub = z_meters.sel(number=member_ids)\n",
        "\n",
        "    # ensemble mean over provided members + time window\n",
        "    ens_mean = z_sub.sel(step=steps_arr[sel]).mean(dim=(\"number\", \"step\"))  # [lat, lon]\n",
        "\n",
        "    # clusters to show (up to 4)\n",
        "    uniq = np.unique(labels)\n",
        "    if clusters_to_show is None:\n",
        "        clusters_to_show = uniq[:4]\n",
        "    else:\n",
        "        clusters_to_show = np.asarray(clusters_to_show)[:4]\n",
        "\n",
        "    # compute cluster means and anomalies (cluster - ensemble) for color scaling\n",
        "    cluster_fields = []\n",
        "    diffs = []\n",
        "    counts = []\n",
        "    for c in clusters_to_show:\n",
        "        mask = labels == c\n",
        "        counts.append(int(mask.sum()))\n",
        "        if counts[-1] == 0:\n",
        "            # Empty cluster; fill with NaNs\n",
        "            cl_mean = xr.full_like(ens_mean, np.nan)\n",
        "        else:\n",
        "            mids = member_ids[mask]\n",
        "            cl_mean = z_sub.sel(number=mids, step=steps_arr[sel]).mean(dim=(\"number\", \"step\"))\n",
        "        cluster_fields.append(cl_mean)\n",
        "        diffs.append((cl_mean - ens_mean))\n",
        "\n",
        "    # consistent symmetric color limits across cluster panels\n",
        "    if symmetric_shade:\n",
        "        vmax = np.nanmax([np.nanmax(np.abs(d.values)) for d in diffs if d is not None])\n",
        "        if not np.isfinite(vmax) or vmax == 0:\n",
        "            vmax = None\n",
        "    else:\n",
        "        vmax = None\n",
        "\n",
        "    # unit conversion\n",
        "    unit_factor = 1.0 if units == \"m\" else 0.1  # meters->dam\n",
        "    ens_mean_plot = ens_mean * unit_factor\n",
        "    diffs_plot = [d * unit_factor for d in diffs]\n",
        "    cluster_fields_plot = [c * unit_factor for c in cluster_fields]\n",
        "    unit_label = \"m\" if units == \"m\" else \"dam\"\n",
        "\n",
        "    # lon/lat mesh for pcolormesh/contour\n",
        "    Lon, Lat = np.meshgrid(z_meters.longitude.values, z_meters.latitude.values)\n",
        "\n",
        "    # projection default\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    # --- figure layout: 2 rows x 3 cols; last axis is empty\n",
        "    fig = plt.figure(figsize=(14, 8))\n",
        "    axes = []\n",
        "    for i in range(6):\n",
        "        ax = plt.subplot(2, 3, i+1, projection=projection) if i < 5 else plt.subplot(2, 3, i+1)\n",
        "        axes.append(ax)\n",
        "\n",
        "    # plot 4 cluster panels\n",
        "    for i, (c, cl_mean, diff, n) in enumerate(zip(clusters_to_show, cluster_fields_plot, diffs_plot, counts)):\n",
        "        ax = axes[i]\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "        # shaded anomaly vs ensemble mean\n",
        "        if vmax is not None:\n",
        "            pm = ax.pcolormesh(Lon, Lat, diff, shading=\"auto\", cmap=cmap,\n",
        "                               vmin=-vmax, vmax=+vmax, transform=ccrs.PlateCarree())\n",
        "        else:\n",
        "            pm = ax.pcolormesh(Lon, Lat, diff, shading=\"auto\", cmap=cmap, transform=ccrs.PlateCarree())\n",
        "        # mean height contours (cluster mean)\n",
        "        cs = ax.contour(Lon, Lat, cl_mean, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "                        transform=ccrs.PlateCarree())\n",
        "        ax.clabel(cs, fmt=\"%.0f\" if units == \"m\" else \"%.1f\", fontsize=8)\n",
        "\n",
        "        # cartographic layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "\n",
        "        ax.set_title(f\"Cluster {c} (n={n}); shaded: Δ vs ens mean\")\n",
        "\n",
        "        # add a colorbar only once (right side)\n",
        "        if i == 0:\n",
        "            cax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
        "            cb = fig.colorbar(pm, cax=cax, label=f\"Anomaly ({unit_label})\")\n",
        "\n",
        "    # panel 5: ensemble mean contours only\n",
        "    ax5 = axes[4]\n",
        "    ax5.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "    cs5 = ax5.contour(Lon, Lat, ens_mean_plot, levels=n_contours, colors=\"k\", linewidths=0.9,\n",
        "                      transform=ccrs.PlateCarree())\n",
        "    ax5.clabel(cs5, fmt=\"%.0f\" if units == \"m\" else \"%.1f\", fontsize=8)\n",
        "    ax5.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "    ax5.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "    ax5.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "    ax5.set_title(f\"Ensemble mean {unit_label} ({s0}–{s1} h)\")\n",
        "\n",
        "    # panel 6: turn off\n",
        "    axes[5].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(title, y=0.98, fontsize=12)\n",
        "    plt.tight_layout(rect=[0, 0, 0.9, 0.96])\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "########################## Clustering & Plotting ##############################\n",
        "\n",
        "# 1) Load\n",
        "ds = xr.open_dataset(\n",
        "    path,\n",
        "    engine=\"cfgrib\"\n",
        ")\n",
        "\n",
        "# Optional: normalize longitudes to -180..180 if dataset is 0..360\n",
        "if ds.longitude.max() > 180:\n",
        "    ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180).sortby(\"longitude\")\n",
        "\n",
        "# 2) Subset time + bbox\n",
        "lat_min, lat_max = 40, 75\n",
        "lon_min, lon_max = -179, -125\n",
        "\n",
        "subset = ds.sel(\n",
        "    step=slice(np.timedelta64(tr[0], \"h\"), np.timedelta64(tr[1], \"h\")),\n",
        "    latitude=slice(lat_max, lat_min),      # lat usually decreasing\n",
        "    longitude=slice(lon_min, lon_max)\n",
        ")\n",
        "\n",
        "# 3) Convert to meters\n",
        "z_meters = subset[\"gh\"] / 9.80665   # dims: number, step, latitude, longitude\n",
        "\n",
        "# 4) Latitude weights (sqrt(cos(lat))) over the latitude dimension\n",
        "lat = z_meters[\"latitude\"]\n",
        "wlat = np.sqrt(np.clip(np.cos(np.deg2rad(lat)), 0, None))\n",
        "weights = xr.DataArray(wlat, dims=[\"latitude\"], coords={\"latitude\": lat})\n",
        "\n",
        "# Apply weights (broadcast over step/number/longitude automatically)\n",
        "weighted = z_meters * weights\n",
        "\n",
        "# 5) Stack features AFTER weighting\n",
        "features = weighted.stack(features=(\"step\", \"latitude\", \"longitude\"))  # dims: number, features\n",
        "X = features.values  # shape: [n_members, n_features]\n",
        "\n",
        "# 6) Handle NaNs\n",
        "# Identify members (rows) with any NaNs\n",
        "bad_members_mask = np.any(np.isnan(X), axis=1)\n",
        "\n",
        "if np.any(bad_members_mask):\n",
        "    bad_ids = z_meters['number'].values[bad_members_mask]\n",
        "    print(f\"Dropping members with missing data: {bad_ids}\")\n",
        "\n",
        "    # Keep only rows without NaNs\n",
        "    X = X[~bad_members_mask, :]\n",
        "    member_ids = z_meters['number'].values[~bad_members_mask]\n",
        "else:\n",
        "    print(\"All members have complete data.\")\n",
        "    member_ids = z_meters['number'].values\n",
        "\n",
        "# Weighted anomalies (subtract mean, don't scale by std)\n",
        "X_anoms = StandardScaler(with_mean=True, with_std=False).fit_transform(X)\n",
        "\n",
        "# 7) PCA to 2 components\n",
        "pca = PCA(n_components=2)\n",
        "pcs = pca.fit_transform(X_anoms)\n",
        "print(f\"Explained variance (2 PCs): {pca.explained_variance_ratio_.sum():.2%}\")\n",
        "\n",
        "# 8) K-means in PC space\n",
        "n_clusters = 4\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "labels = kmeans.fit_predict(pcs)\n",
        "\n",
        "# 9) Members per cluster\n",
        "clusters = {i: [] for i in range(n_clusters)}\n",
        "for m_idx, cid in enumerate(labels):\n",
        "    clusters[cid].append(int(z_meters[\"number\"][m_idx].values))\n",
        "\n",
        "for cid, members in clusters.items():\n",
        "    print(f\"Cluster {cid}: {members}\")\n",
        "\n",
        "# Plotting EOFs\n",
        "fig1, fig2 = plot_mean_height_with_eof_shade_cartopy(\n",
        "    z_meters, pca,\n",
        "    window=tr,\n",
        "    eof_indices=(0, 1),\n",
        "    projection=ccrs.NorthPolarStereo(central_longitude=-150, true_scale_latitude=60),\n",
        "    scale=\"1sigma\"            # 1-σ amplitude patterns (meters)\n",
        ")\n",
        "\n",
        "# Plotting phase space\n",
        "member_ids = z_meters[\"number\"].values    # or the filtered array if you dropped members\n",
        "\n",
        "fig = plot_pc_phase_space(\n",
        "    pcs=pcs,\n",
        "    labels=labels,\n",
        "    member_ids=member_ids,\n",
        "    pca=pca,\n",
        "    cluster_centers=getattr(kmeans, \"cluster_centers_\", None),\n",
        "    title=\"ECMWF ENS 500 hPa — Phase Space (PC1 vs PC2)\"\n",
        ")\n",
        "\n",
        "representatives = pick_cluster_representatives(\n",
        "    pcs=pcs,\n",
        "    labels=labels,\n",
        "    member_ids=member_ids,\n",
        "    pca=pca,\n",
        "    standardize=True,                       # matches your standardized phase-space\n",
        "    centers=getattr(kmeans, \"cluster_centers_\", None),\n",
        "    n_components=2\n",
        ")\n",
        "\n",
        "print(representatives)\n",
        "\n",
        "fig = plot_cluster_composites_500hpa(\n",
        "    z_meters=z_meters,\n",
        "    labels=labels,\n",
        "    member_ids=member_ids,     # if you didn't drop any, you can omit this\n",
        "    window=tr,\n",
        "    units=\"m\"                # contours + anomalies in decameters\n",
        ")"
      ],
      "metadata": {
        "id": "JLdCf63WUlLl",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Plot Representative Member**"
      ],
      "metadata": {
        "id": "PxyQRqigV0dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=UserWarning\n",
        ")\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning\n",
        ")\n",
        "\n",
        "################## Color Map Generation ###################################\n",
        "def make_custom_cmaps(name, colors, bounds: list = None, N: int = None):\n",
        "    if N is None:\n",
        "        N = len(colors)\n",
        "    linear_cmap = mcolors.LinearSegmentedColormap.from_list(name, colors)\n",
        "    segment_cmap = mcolors.LinearSegmentedColormap.from_list(name + \"2\", colors, N=N)\n",
        "\n",
        "    # When data is NaN, set color to transparent\n",
        "    linear_cmap.set_bad(\"#ffffff00\")\n",
        "    segment_cmap.set_bad(\"#ffffff00\")\n",
        "\n",
        "    for cm in [linear_cmap, segment_cmap]:\n",
        "        mpl.colormaps.register(cmap=cm, force=True)\n",
        "        mpl.colormaps.register(cmap=cm.reversed(), force=True)\n",
        "\n",
        "    if bounds is not None:\n",
        "        return (\n",
        "            mcolors.Normalize(bounds.min(), bounds.max()),\n",
        "            mcolors.BoundaryNorm(bounds, linear_cmap.N),\n",
        "        )\n",
        "\n",
        "class NWSWindSpeed:\n",
        "    name = \"nws.wind\"\n",
        "    units = r\"mph\"\n",
        "    variable = \"Wind Speed\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#103f78\",\n",
        "            \"#225ea8\",\n",
        "            \"#1d91c0\",\n",
        "            \"#41b6c4\",\n",
        "            \"#7fcdbb\",\n",
        "            \"#b4d79e\",\n",
        "            \"#dfff9e\",\n",
        "            \"#ffffa6\",\n",
        "            \"#ffe873\",\n",
        "            \"#ffc400\",\n",
        "            \"#ffaa00\",\n",
        "            \"#ff5900\",\n",
        "            \"#ff0000\",\n",
        "            \"#a80000\",\n",
        "            \"#6e0000\",\n",
        "            \"#ffbee8\",\n",
        "            \"#ff73df\",\n",
        "        ]\n",
        "    )\n",
        "    # MPH\n",
        "    bounds = np.array(\n",
        "        [0.0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 100, 120, 140, 160]\n",
        "    )\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"proportional\", ticks=bounds)\n",
        "\n",
        "class NWSWindSpeedkts:\n",
        "    name = \"nws.wind\"\n",
        "    units = r\"kts\"\n",
        "    variable = \"Wind Speed\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#103f78\",\n",
        "            \"#225ea8\",\n",
        "            \"#1d91c0\",\n",
        "            \"#41b6c4\",\n",
        "            \"#7fcdbb\",\n",
        "            \"#b4d79e\",\n",
        "            \"#dfff9e\",\n",
        "            \"#ffffa6\",\n",
        "            \"#ffe873\",\n",
        "            \"#ffc400\",\n",
        "            \"#ffaa00\",\n",
        "            \"#ff5900\",\n",
        "            \"#ff0000\",\n",
        "            \"#a80000\",\n",
        "            \"#6e0000\",\n",
        "            \"#ffbee8\",\n",
        "            \"#ff73df\",\n",
        "        ]\n",
        "    )\n",
        "    # kts\n",
        "    bounds = np.array(\n",
        "        [0.0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 100, 120, 140, 160]\n",
        "    )\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"proportional\", ticks=bounds)\n",
        "\n",
        "class NWSPrecipitation:\n",
        "    \"\"\"National Weather Service precipitation amount colorbar properties.\n",
        "\n",
        "    Also known as Qualitative Precipitation Forecast/Estimate (QPF/QPE).\n",
        "    \"\"\"\n",
        "\n",
        "    name = \"nws.pcp\"\n",
        "    units = \"in\"\n",
        "    variable = \"Precipitation\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#ffffff\",\n",
        "            \"#c7e9c0\",\n",
        "            \"#a1d99b\",\n",
        "            \"#74c476\",\n",
        "            \"#31a353\",\n",
        "            \"#006d2c\",\n",
        "            \"#fffa8a\",\n",
        "            \"#ffcc4f\",\n",
        "            \"#fe8d3c\",\n",
        "            \"#fc4e2a\",\n",
        "            \"#d61a1c\",\n",
        "            \"#ad0026\",\n",
        "            \"#700026\",\n",
        "            \"#3b0030\",\n",
        "            \"#4c0073\",\n",
        "            \"#ffdbff\",\n",
        "        ]\n",
        "    )\n",
        "    # NWS bounds in inches\n",
        "    bounds = np.array(\n",
        "        [0, 0.01, 0.1, 0.25, 0.5, 1, 1.5, 2, 3, 4, 6, 8, 10, 15, 20, 30, 50]\n",
        "    )\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"uniform\", ticks=bounds)\n",
        "\n",
        "class NWSPrecipitationSnow:\n",
        "    name = \"nws.pcp_snow\"\n",
        "    units = \"in\"\n",
        "    variable = \"Snow\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#ffffff\",\n",
        "            \"#bdd7e7\",\n",
        "            \"#6baed6\",\n",
        "            \"#3182bd\",\n",
        "            \"#08519c\",\n",
        "            \"#082694\",\n",
        "            \"#ffff96\",\n",
        "            \"#ffc400\",\n",
        "            \"#ff8700\",\n",
        "            \"#db1400\",\n",
        "            \"#9e0000\",\n",
        "            \"#690000\",\n",
        "            \"#360000\",\n",
        "        ]\n",
        "    )\n",
        "    # NWS bounds in inches\n",
        "    bounds = np.array([0, 0.1, 1, 2, 3, 4, 6, 8, 12, 18, 24, 30, 36, 42])\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"uniform\", ticks=bounds)\n",
        "\n",
        "class NWS850Temperature:\n",
        "    name = \"nws.tmp850\"\n",
        "    variable = \"850 mb Temperature\"\n",
        "    units = r\"$^\\circ$C\"\n",
        "\n",
        "    # One color per interval between these ticks (24 ticks → 23 colors)\n",
        "    bounds = np.array([\n",
        "        -50, -45, -40, -35, -30, -25, -20, -15, -10, -5,\n",
        "          0,   3,   6,   9,  12,  15,  18,  21,  24,  27,\n",
        "         30,  33,  36,  39\n",
        "    ], dtype=float)\n",
        "\n",
        "    colors = np.array(['#08306b', '#0c3b75', '#11477f', '#15528a', '#195d94', '#1e699e', '#2274a8',\n",
        "    '#267fb3', '#2b8cbe', '#65abd0', '#a0cae3', '#dceaf6', '#fee8c8', '#fedfbb',\n",
        "    '#fed7ae', '#fdcea1', '#fdc593', '#fdbd87', '#f3a172', '#e6815b', '#d96144',\n",
        "    '#cd412e', '#c02017', '#b30000'])\n",
        "\n",
        "    # If you’re using your existing helper:\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap  = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs  = dict(cmap=cmap,  norm=norm)   # continuous\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)   # binned (BoundaryNorm)\n",
        "    cbar_kwargs  = dict(label=f\"{variable} ({units})\", ticks=bounds)\n",
        "    cbar_kwargs2 = dict(label=f\"{variable} ({units})\",\n",
        "                        ticks=bounds, spacing=\"proportional\")\n",
        "\n",
        "\n",
        "class NWSTemperature:\n",
        "    name = \"nws.tmp\"\n",
        "    units = r\"$\\degree$F\"\n",
        "    variable = \"Temperature\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#91003f\",\n",
        "            \"#ce1256\",\n",
        "            \"#e7298a\",\n",
        "            \"#df65b0\",\n",
        "            \"#ff73df\",\n",
        "            \"#ffbee8\",\n",
        "            \"#ffffff\",\n",
        "            \"#dadaeb\",\n",
        "            \"#bcbddc\",\n",
        "            \"#9e9ac8\",\n",
        "            \"#756bb1\",\n",
        "            \"#54278f\",\n",
        "            \"#0d007d\",\n",
        "            \"#0d3d9c\",\n",
        "            \"#0066c2\",\n",
        "            \"#299eff\",\n",
        "            \"#4ac7ff\",\n",
        "            \"#73d7ff\",\n",
        "            \"#adffff\",\n",
        "            \"#30cfc2\",\n",
        "            \"#009996\",\n",
        "            \"#125757\",\n",
        "            \"#066d2c\",\n",
        "            \"#31a354\",\n",
        "            \"#74c476\",\n",
        "            \"#a1d99b\",\n",
        "            \"#d3ffbe\",\n",
        "            \"#ffffb3\",\n",
        "            \"#ffeda0\",\n",
        "            \"#fed176\",\n",
        "            \"#feae2a\",\n",
        "            \"#fd8d3c\",\n",
        "            \"#fc4e2a\",\n",
        "            \"#e31a1c\",\n",
        "            \"#b10026\",\n",
        "            \"#800026\",\n",
        "            \"#590042\",\n",
        "            \"#280028\",\n",
        "        ]\n",
        "    )\n",
        "    # NWS bounds in Fahrenheit\n",
        "    bounds = np.linspace(-65, 125, len(colors) + 1)\n",
        "    # Convert to Celsius (approximate)\n",
        "    #bounds = (bounds - 30) / 2\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"proportional\", ticks=bounds[1::2])\n",
        "\n",
        "class NWSRelativeHumidity:\n",
        "    name = \"nws.rh\"\n",
        "    units = \"%\"\n",
        "    variable = \"Relative Humidity\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#910022\",\n",
        "            \"#a61122\",\n",
        "            \"#bd2e24\",\n",
        "            \"#d44e33\",\n",
        "            \"#e36d42\",\n",
        "            \"#fa8f43\",\n",
        "            \"#fcad58\",\n",
        "            \"#fed884\",\n",
        "            \"#fff2aa\",\n",
        "            \"#e6f49d\",\n",
        "            \"#bce378\",\n",
        "            \"#71b55c\",\n",
        "            \"#26914b\",\n",
        "            \"#00572e\",\n",
        "        ]\n",
        "    )\n",
        "    bounds = np.array([0, 5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100])\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"proportional\", ticks=bounds)\n",
        "\n",
        "def edges_from_ticks(ticks):\n",
        "    t = np.asarray(ticks, float)\n",
        "    mids = 0.5 * (t[:-1] + t[1:])\n",
        "    left  = t[0]  - 0.5 * (t[1]  - t[0])\n",
        "    right = t[-1] + 0.5 * (t[-1] - t[-2])\n",
        "    return np.r_[left, mids, right]\n",
        "\n",
        "class NWS850TempHSV:\n",
        "    name = \"nws.tmp850.hsv\"\n",
        "    variable = \"850 mb Temperature\"\n",
        "    units = r\"$^\\circ$C\"\n",
        "\n",
        "    ticks = np.array([\n",
        "        -50, -45, -40, -35, -30, -25, -20, -15, -10, -5,\n",
        "          0,   3,   6,   9,  12,  15,  18,  21,  24,  27,\n",
        "         30,  33,  36,  39\n",
        "    ], dtype=float)\n",
        "    bounds = edges_from_ticks(ticks)\n",
        "\n",
        "    # Colormap\n",
        "    cmap = plt.get_cmap(\"hsv_r\")\n",
        "\n",
        "    # Continuous usage (pcolormesh/imshow)\n",
        "    norm  = Normalize(vmin=ticks.min(), vmax=ticks.max())\n",
        "    kwargs  = dict(cmap=cmap, norm=norm)\n",
        "\n",
        "    # Optional: center around 0 (note: hsv is cyclic, so centering doesn't create a true cold/warm split)\n",
        "    norm_centered = TwoSlopeNorm(vmin=ticks.min(), vcenter=0.0, vmax=ticks.max())\n",
        "    kwargs_centered = dict(cmap=cmap, norm=norm_centered)\n",
        "\n",
        "    # Discrete/binned usage (contourf with your tick intervals)\n",
        "    norm_bins = BoundaryNorm(bounds, ncolors=cmap.N, clip=True)\n",
        "    kwargs_bins = dict(cmap=cmap, norm=norm_bins)\n",
        "\n",
        "    cbar_kwargs  = dict(label=f\"{variable} ({units})\", ticks=ticks)\n",
        "    cbar_kwargs2 = dict(label=f\"{variable} ({units})\", ticks=ticks, spacing=\"proportional\")\n",
        "\n",
        "#################### Plotting & Helper Functions ###############################\n",
        "\n",
        "def mm_to_in(mm):\n",
        "  return mm * 0.0393701\n",
        "\n",
        "def ms_to_mph(ms):\n",
        "  return ms * 2.23694\n",
        "\n",
        "def ms_to_kts(ms):\n",
        "  return ms * 1.94384\n",
        "\n",
        "def plot_towns(ax, south, north, west, east, population=5000, resolution='10m', transform=ccrs.PlateCarree(), zorder=3):\n",
        "    \"\"\"\n",
        "    This function will download the 'populated_places' shapefile from\n",
        "    NaturalEarth, trim the shapefile based on the limits of the provided\n",
        "    lat & long coords, and then plot the locations and names of the towns\n",
        "    on a given GeoAxes.\n",
        "\n",
        "    ax = a pyplot axes object\n",
        "    south = south lat limit (float)\n",
        "    north = north lat limit (float)\n",
        "    west = west long limit (float)\n",
        "    east = east long limit (float)\n",
        "    resolution= str. either high res:'10m' or low res: '50m'\n",
        "    population = minimum population of towns to plot (int)\n",
        "    transform = a cartopy crs object\n",
        "    \"\"\"\n",
        "    #get town locations\n",
        "    shp_fn = shpreader.natural_earth(resolution=resolution, category='cultural', name='populated_places')\n",
        "    shp = shpreader.Reader(shp_fn)\n",
        "    xy = [pt.coords[0] for pt in shp.geometries()]\n",
        "    x, y = list(zip(*xy))\n",
        "\n",
        "    #get town names\n",
        "    towns = shp.records()\n",
        "    names_en = []\n",
        "    max_population = []\n",
        "    for town in towns:\n",
        "        #print(town.attributes)\n",
        "        names = town.attributes['NAME']\n",
        "        pop = town.attributes['POP_MAX']\n",
        "        names_en.append(names)\n",
        "        max_population.append(pop)\n",
        "    #print(names_en)\n",
        "    #create data frame and index by the region of the plot\n",
        "    all_towns = pd.DataFrame({'names_en': names_en, 'x':x, 'y':y, 'population':max_population})\n",
        "    #print(all_towns.head())\n",
        "    region_towns = all_towns[(all_towns.y<north) & (all_towns.y>south)\n",
        "                           & (all_towns.x>west) & (all_towns.x<east)]\n",
        "    region_towns = region_towns[region_towns.population > population]\n",
        "    #print(region_towns.head())\n",
        "    #plot the locations and labels of the towns in the region\n",
        "    ax.scatter(region_towns.x.values, region_towns.y.values, c ='black', marker= '.', transform=transform, zorder=zorder)\n",
        "    transform_mpl = ccrs.PlateCarree()._as_mpl_transform(ax) #this is a work-around to transform xy coords in ax.annotate\n",
        "    for i, txt in enumerate(region_towns.names_en):\n",
        "         ax.annotate(txt, (region_towns.x.values[i], region_towns.y.values[i]), xycoords=transform_mpl)\n",
        "\n",
        "def plot_msl_with_tp6h(\n",
        "    ds,\n",
        "    *,\n",
        "    lat_min=50, lat_max=72,\n",
        "    lon_min=-180, lon_max=-130,\n",
        "    projection=None,\n",
        "    coast_res=\"50m\",\n",
        "    tp_mm_max=4,            # colorbar cap for 6-h precip (in)\n",
        "    n_contours=20,\n",
        "    clip_negative=True,       # clip tiny negative diffs to 0\n",
        "    plot_cities=False,\n",
        "    pop_filter=2000,\n",
        "    smooth_pressure = False\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots one map per 6-h accumulation step:\n",
        "      - MSLP (hPa) as contours\n",
        "      - 6-h precipitation (mm) as shaded\n",
        "\n",
        "    Assumes ds has cumulative 'tp' (meters) at steps including the previous step.\n",
        "    The first original step is NOT plotted; tp6 is aligned to the 'upper' steps only.\n",
        "    \"\"\"\n",
        "    # Normalize longitudes to [-180, 180] if needed\n",
        "    if float(ds.longitude.max()) > 180:\n",
        "        ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180).sortby(\"longitude\")\n",
        "\n",
        "    # Subset bbox (lat usually decreasing in GRIB)\n",
        "    ds_box = ds.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
        "\n",
        "    # Convert units\n",
        "    msl_hpa = ds_box[\"msl\"] / 100.0         # Pa -> hPa\n",
        "\n",
        "    tp_cum  = ds_box[\"tp\"]                  # meters, cumulative since T0\n",
        "    #print(tp_cum)\n",
        "    #print(tp_cum.shape)\n",
        "\n",
        "    # Make sure steps are sorted, and compute 6-h accumulation robustly\n",
        "    tp_cum = tp_cum.sortby(\"step\")\n",
        "\n",
        "    if tp_cum.sizes.get(\"step\", 0) > 1:\n",
        "        # interval = cum(t) - cum(t-1 step), align to the \"upper\" step\n",
        "        tp6 = tp_cum - tp_cum.shift(step=1)\n",
        "        tp6 = tp6.isel(step=slice(1, None))               # drop first NaN\n",
        "        # relabel the step coordinate to the \"upper\" times\n",
        "        tp6 = tp6.assign_coords(step=tp_cum.step.isel(step=slice(1, None)))\n",
        "        # meters -> mm -> inches (or keep mm if you prefer)\n",
        "        tp6 = mm_to_in(tp6 * 1000.0)\n",
        "        if clip_negative:\n",
        "            tp6 = xr.where(tp6 < 0, 0, tp6)\n",
        "        plot_title_prefix = \"MSLP (hPa) contours + 6-h precip (in) shaded\"\n",
        "    else:\n",
        "        # Only one step: plot total\n",
        "        tp6 = mm_to_in(tp_cum * 1000.0)\n",
        "        plot_title_prefix = \"MSLP (hPa) contours + Total precip (in) shaded\"\n",
        "\n",
        "    # Mesh for plotting\n",
        "    Lon, Lat = np.meshgrid(ds_box.longitude.values, ds_box.latitude.values)\n",
        "\n",
        "    # Projection\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    # Optional: check spacing ~6h\n",
        "    if \"timedelta64\" in str(ds_box.step.dtype):\n",
        "        dh = (ds_box.step.diff(\"step\") / np.timedelta64(1, \"h\")).astype(float)\n",
        "        if not np.allclose(dh, 6.0):\n",
        "            print(\"⚠️  Step spacing is not uniformly 6 h; plotting interval accumulations as-is.\")\n",
        "\n",
        "    # Loop over *tp6* steps (skips the first original step by construction)\n",
        "    for i, step_val in enumerate(tp6.step.values):\n",
        "        z = msl_hpa.sel(step=step_val)\n",
        "        if smooth_pressure:\n",
        "            z = ndimage.gaussian_filter(z, sigma=2)\n",
        "        p = tp6.sel(step=step_val)\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 6))\n",
        "        ax = plt.axes(projection=projection)\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "\n",
        "        # shaded 6-h precip (mm)\n",
        "        #pm = ax.pcolormesh(Lon, Lat, p, cmap=cmap, shading=\"auto\",\n",
        "        #                   vmin=0, vmax=tp_mm_max, transform=ccrs.PlateCarree())\n",
        "        kwargs = NWSPrecipitation.kwargs2\n",
        "        cbar_kwargs = NWSPrecipitation.cbar_kwargs2\n",
        "\n",
        "        pm = ax.pcolormesh(Lon, Lat, p, transform=ccrs.PlateCarree(), **kwargs)\n",
        "        plt.colorbar(pm, ax=ax, pad=0.02, **cbar_kwargs)\n",
        "\n",
        "        # MSLP contours (hPa)\n",
        "        cs = ax.contour(Lon, Lat, z, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "                        transform=ccrs.PlateCarree())\n",
        "        ax.clabel(cs, fmt=\"%.0f\", fontsize=8)\n",
        "\n",
        "        # carto layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "        gl = ax.gridlines(draw_labels=True, linewidth=0.4, color=\"gray\", alpha=0.4, linestyle=\"--\")\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        # Title\n",
        "        if \"valid_time\" in ds_box:\n",
        "            vt = ds_box.valid_time.sel(step=step_val).values  # numpy.datetime64\n",
        "            # ensure numpy datetime64 and format to hour\n",
        "            tstr = np.datetime_as_string(np.asarray(vt, dtype=\"datetime64[ns]\"), unit=\"h\")\n",
        "        else:\n",
        "            # fall back to lead time\n",
        "            if np.issubdtype(ds_box.step.dtype, np.timedelta64):\n",
        "                lead_h = int(step_val / np.timedelta64(1, \"h\"))\n",
        "                tstr = f\"T+{lead_h:02d} h\"\n",
        "            else:\n",
        "                tstr = str(step_val)\n",
        "        ax.set_title(f\"{plot_title_prefix} — {tstr}\")\n",
        "        #plotting cities if need be\n",
        "        if plot_cities:\n",
        "            plot_towns(ax, south=lat_min, north=lat_max, west=lon_min, east=lon_max, population=pop_filter)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def plot_msl_with_10mwind(\n",
        "    ds,\n",
        "    *,\n",
        "    lat_min=50, lat_max=72,\n",
        "    lon_min=-180, lon_max=-130,\n",
        "    projection=None,\n",
        "    coast_res=\"50m\",\n",
        "    wind_units=\"kts\",\n",
        "    thin_factor = 50,\n",
        "    n_contours=20,\n",
        "    clip_negative=True,\n",
        "    plot_cities=False,\n",
        "    pop_filter=2000,\n",
        "    smooth_pressure = False\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots one map per 6-h accumulation step:\n",
        "      - MSLP (hPa) as contours\n",
        "      - 10m Wind as shaded with barbs\n",
        "\n",
        "    \"\"\"\n",
        "    # Normalize longitudes to [-180, 180] if needed\n",
        "    if float(ds.longitude.max()) > 180:\n",
        "        ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180).sortby(\"longitude\")\n",
        "\n",
        "    # Subset bbox (lat usually decreasing in GRIB)\n",
        "    ds_box = ds.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
        "\n",
        "    # Convert units\n",
        "    msl_hpa = ds_box[\"msl\"] / 100.0         # Pa -> hPa\n",
        "    # smoothing pressure if need be\n",
        "    if smooth_pressure:\n",
        "        msl_hpa = ndimage.gaussian_filter(msl_hpa, sigma=2)\n",
        "    if wind_units == \"kts\":\n",
        "        uwind = ms_to_kts(ds_box[\"u10\"])\n",
        "        vwind = ms_to_kts(ds_box[\"v10\"])\n",
        "    else:\n",
        "        uwind = ms_to_mph(ds_box[\"u10\"])\n",
        "        vwind = ms_to_mph(ds_box[\"v10\"])\n",
        "\n",
        "    #calculating the magnitude and converting units\n",
        "    wind_mag = np.sqrt(uwind**2 + vwind**2)\n",
        "\n",
        "    # Mesh for plotting\n",
        "    Lon, Lat = np.meshgrid(ds_box.longitude.values, ds_box.latitude.values)\n",
        "    #print(\n",
        "    # Projection\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    # Optional: check spacing ~6h\n",
        "    if \"timedelta64\" in str(ds_box.step.dtype):\n",
        "        dh = (ds_box.step.diff(\"step\") / np.timedelta64(1, \"h\")).astype(float)\n",
        "        if not np.allclose(dh, 6.0):\n",
        "            print(\"⚠️  Step spacing is not uniformly 6 h; plotting interval accumulations as-is.\")\n",
        "\n",
        "    # Loop over time steps\n",
        "    for i, step_val in enumerate(wind_mag.step.values):\n",
        "        z = msl_hpa.sel(step=step_val)\n",
        "        p = wind_mag.sel(step=step_val)\n",
        "        u = uwind.sel(step=step_val)\n",
        "        v = vwind.sel(step=step_val)\n",
        "        u = u[::thin_factor, ::thin_factor]\n",
        "        v = v[::thin_factor, ::thin_factor]\n",
        "        lon_barbs = Lon[::thin_factor, ::thin_factor]\n",
        "        lat_barbs = Lat[::thin_factor, ::thin_factor]\n",
        "        fig = plt.figure(figsize=(10, 6))\n",
        "        ax = plt.axes(projection=projection)\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "\n",
        "        # shaded 6-h precip (mm)\n",
        "        #pm = ax.pcolormesh(Lon, Lat, p, cmap=cmap, shading=\"auto\",\n",
        "        #                   vmin=0, vmax=tp_mm_max, transform=ccrs.PlateCarree())\n",
        "        if wind_units == \"kts\":\n",
        "            kwargs = NWSWindSpeedkts.kwargs2\n",
        "            cbar_kwargs = NWSWindSpeedkts.cbar_kwargs2\n",
        "        else:\n",
        "            kwargs = NWSWindSpeed.kwargs2\n",
        "            cbar_kwargs = NWSWindSpeed.cbar_kwargs2\n",
        "\n",
        "        pm = ax.pcolormesh(Lon, Lat, p, transform=ccrs.PlateCarree(), **kwargs)\n",
        "        plt.colorbar(pm, ax=ax, pad=0.02, **cbar_kwargs)\n",
        "\n",
        "        # MSLP contours (hPa)\n",
        "        cs = ax.contour(Lon, Lat, z, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "                        transform=ccrs.PlateCarree())\n",
        "        # Adding wind barbs\n",
        "        ax.barbs(lon_barbs, lat_barbs, u.values, v.values, length=6, transform=ccrs.PlateCarree())\n",
        "        ax.clabel(cs, fmt=\"%.0f\", fontsize=8)\n",
        "\n",
        "        # carto layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "        gl = ax.gridlines(draw_labels=True, linewidth=0.4, color=\"gray\", alpha=0.4, linestyle=\"--\")\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        # Title\n",
        "        if \"valid_time\" in ds_box:\n",
        "            vt = ds_box.valid_time.sel(step=step_val).values  # numpy.datetime64\n",
        "            # ensure numpy datetime64 and format to hour\n",
        "            tstr = np.datetime_as_string(np.asarray(vt, dtype=\"datetime64[ns]\"), unit=\"h\")\n",
        "        else:\n",
        "            # fall back to lead time\n",
        "            if np.issubdtype(ds_box.step.dtype, np.timedelta64):\n",
        "                lead_h = int(step_val / np.timedelta64(1, \"h\"))\n",
        "                tstr = f\"T+{lead_h:02d} h\"\n",
        "            else:\n",
        "                tstr = str(step_val)\n",
        "        ax.set_title(f\"MSLP (hPa) contours + 10m wind shaded — {tstr}\")\n",
        "        if plot_cities:\n",
        "            plot_towns(ax, south=lat_min, north=lat_max, west=lon_min, east=lon_max, population=pop_filter)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def plot_upper_level_temps(\n",
        "    ds,\n",
        "    *,\n",
        "    lat_min=50, lat_max=72,\n",
        "    lon_min=-180, lon_max=-130,\n",
        "    projection=None,\n",
        "    level=850,\n",
        "    coast_res=\"50m\",\n",
        "    n_contours=20,\n",
        "    clip_negative=True,\n",
        "    plot_cities=False,\n",
        "    pop_filter=2000\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots one map per 6-h time step:\n",
        "      - upper level height as contours\n",
        "      - upper level temp as shaded\n",
        "\n",
        "    \"\"\"\n",
        "    # Normalize longitudes to [-180, 180] if needed\n",
        "    if float(ds.longitude.max()) > 180:\n",
        "        ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180).sortby(\"longitude\")\n",
        "\n",
        "    # Subset bbox (lat usually decreasing in GRIB)\n",
        "    ds_box = ds.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
        "\n",
        "    # Convert units\n",
        "    gh = ds_box[\"gh\"]\n",
        "    temp = ds_box[\"t\"] -273 # converting to C\n",
        "\n",
        "    # Mesh for plotting\n",
        "    Lon, Lat = np.meshgrid(ds_box.longitude.values, ds_box.latitude.values)\n",
        "    #print(\n",
        "    # Projection\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    # Optional: check spacing ~6h\n",
        "    if \"timedelta64\" in str(ds_box.step.dtype):\n",
        "        dh = (ds_box.step.diff(\"step\") / np.timedelta64(1, \"h\")).astype(float)\n",
        "        if not np.allclose(dh, 6.0):\n",
        "            print(\"⚠️  Step spacing is not uniformly 6 h; plotting interval accumulations as-is.\")\n",
        "\n",
        "    # Loop over time steps\n",
        "    for i, step_val in enumerate(temp.step.values):\n",
        "        z = gh.sel(step=step_val)\n",
        "        t = temp.sel(step=step_val)\n",
        "        fig = plt.figure(figsize=(10, 6))\n",
        "        ax = plt.axes(projection=projection)\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "\n",
        "        kwargs = NWS850TempHSV.kwargs_centered\n",
        "        cbar_kwargs = NWS850TempHSV.cbar_kwargs2\n",
        "\n",
        "        pm = ax.pcolormesh(Lon, Lat, t, transform=ccrs.PlateCarree(), **kwargs)\n",
        "        plt.colorbar(pm, ax=ax, pad=0.02, **cbar_kwargs)\n",
        "\n",
        "        # Height contours (hPa)\n",
        "        cs = ax.contour(Lon, Lat, z, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "                        transform=ccrs.PlateCarree())\n",
        "        ax.clabel(cs, fmt=\"%.0f\", fontsize=8)\n",
        "        # carto layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "        gl = ax.gridlines(draw_labels=True, linewidth=0.4, color=\"gray\", alpha=0.4, linestyle=\"--\")\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        # Title\n",
        "        if \"valid_time\" in ds_box:\n",
        "            vt = ds_box.valid_time.sel(step=step_val).values  # numpy.datetime64\n",
        "            # ensure numpy datetime64 and format to hour\n",
        "            tstr = np.datetime_as_string(np.asarray(vt, dtype=\"datetime64[ns]\"), unit=\"h\")\n",
        "        else:\n",
        "            # fall back to lead time\n",
        "            if np.issubdtype(ds_box.step.dtype, np.timedelta64):\n",
        "                lead_h = int(step_val / np.timedelta64(1, \"h\"))\n",
        "                tstr = f\"T+{lead_h:02d} h\"\n",
        "            else:\n",
        "                tstr = str(step_val)\n",
        "\n",
        "        ax.set_title(f\"{level}mb height contours + temperature shaded — {tstr}\")\n",
        "        if plot_cities:\n",
        "            plot_towns(ax, south=lat_min, north=lat_max, west=lon_min, east=lon_max, population=pop_filter)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "############################## Config & Markdown ###############################\n",
        "\n",
        "#@markdown Which cluster do you want to see?\n",
        "cluster = \"3\" #@param [0,1,2,3]\n",
        "#@markdown Which variable do you want to plot?\n",
        "wxvar = \"MSLP_Precip\" #@param [\"MSLP_Precip\", \"MSLP_10mWind\", \"850mb_Temps\", \"925mb_Temps\"]\n",
        "#@markdown In what units would you like your wind speed?\n",
        "wind_units = \"kts\" #@param [\"kts\", \"mph\"]\n",
        "\n",
        "#@markdown What time frame do you want to see?\n",
        "timeframe = \"Day5\" #@param [\"Day5\", \"Day6\", \"Day7\", \"Day8\", \"Day9\", \"Day5-7\", \"Day6-8\", \"Day7-9\", \"Day5-8\", \"Day6-9\"]\n",
        "#@markdown Select your zoom area (Full_Extent is the entire state of AK)\n",
        "zoom_area = \"Full_Extent\" #@param [\"Full_Extent\", \"Anchorage_Area\", \"Juneau_Area\", \"Fairbanks_Area\", \"SouthCentral_Wide\", \"SoutheastAK\", \"WestCoast\", \"InteriorAK\"]\n",
        "#@markdown If you're plotting wind, choose your thinning factor for wind barbs (12 is a good number for the full AK domain). For small domains try a smaller number like 5 to 10.\n",
        "thin_factor = 12 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "\n",
        "#\n",
        "zoom_area_dict = {\n",
        "    \"Anchorage_Area\": [59.17, 62.58, -156.29, -146.87],\n",
        "    \"Juneau_Area\": [57.95, 58.83, -135.34, -133.56],\n",
        "    \"Fairbanks_Area\": [63.44, 65.96, -151.91, -140],\n",
        "    \"SouthCentral_Wide\": [57.15, 64.17,-161.67,-139.28],\n",
        "    \"SoutheastAK\": [53.56, 61.11,-142.35,-128.33],\n",
        "    \"WestCoast\": [56.08, 72, -178.57, -150.71],\n",
        "    \"Interior_AK\": [63.43,72,-168.53,-139.58],\n",
        "    \"Full_Extent\": [50, 75, -180, -125]\n",
        "}\n",
        "timeranges = {\n",
        "    \"Day5\": (120, 144),\n",
        "    \"Day6\": (144, 168),\n",
        "    \"Day7\": (168, 192),\n",
        "    \"Day8\": (192, 216),\n",
        "    \"Day9\": (216, 240),\n",
        "    \"Day5-7\": (120, 192),\n",
        "    \"Day6-8\": (144, 216),\n",
        "    \"Day7-9\": (168, 240),\n",
        "    \"Day5-8\": (120, 216),\n",
        "    \"Day6-9\": (144, 240),\n",
        "}\n",
        "tr = timeranges[timeframe]\n",
        "vardict = {\n",
        "    \"MSLP_Precip\": \"MSLP\",\n",
        "}\n",
        "\n",
        "##################### Main Download & Graphics Generation ######################\n",
        "\n",
        "if wxvar == \"MSLP_Precip\":\n",
        "    #getting MSL\n",
        "    path1 = download_ecmwf_ens(\n",
        "        param=['msl', 'tp'],\n",
        "        init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "        steps=list(range(tr[0]-6, tr[1], 6)),\n",
        "        level_type=\"sfc\",\n",
        "        members=[representatives[int(cluster)]],\n",
        "        target_dir=\".\",\n",
        "        source=\"aws\"\n",
        "    )\n",
        "    #path1 = \"ecmwf_ens_msl_tp_sfc_2025081100.grib2\"\n",
        "    # 1) Load\n",
        "    ds = xr.open_dataset(\n",
        "        path1,\n",
        "        engine=\"cfgrib\"\n",
        "    )\n",
        "    # ds is your Dataset with coords and variables: step, latitude, longitude, msl, tp\n",
        "    if zoom_area == \"Full_Extent\":\n",
        "      plot_msl_with_tp6h(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          tp_mm_max=30,              # adjust colorbar cap as you like\n",
        "          n_contours=20,\n",
        "          smooth_pressure=False\n",
        "      )\n",
        "    else:\n",
        "      plot_msl_with_tp6h(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          tp_mm_max=30,              # adjust colorbar cap as you like\n",
        "          n_contours=20,\n",
        "          plot_cities=True,\n",
        "          pop_filter=500,\n",
        "          smooth_pressure=True\n",
        "      )\n",
        "elif wxvar == \"MSLP_10mWind\":\n",
        "    #getting MSL\n",
        "    path1 = download_ecmwf_ens(\n",
        "        param=['msl', '10u', '10v'],\n",
        "        init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "        steps=list(range(tr[0]-6, tr[1], 6)),\n",
        "        level_type=\"sfc\",\n",
        "        members=[representatives[int(cluster)]],\n",
        "        target_dir=\".\",\n",
        "        source=\"aws\"\n",
        "    )\n",
        "\n",
        "    # 1) Load\n",
        "    ds = xr.open_dataset(\n",
        "        path1,\n",
        "        engine=\"cfgrib\"\n",
        "    )\n",
        "    # ds is your Dataset with coords and variables: step, latitude, longitude, msl, tp\n",
        "    if zoom_area == \"Full_Extent\":\n",
        "      plot_msl_with_10mwind(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          wind_units=wind_units,\n",
        "          thin_factor=thin_factor,\n",
        "          n_contours=20,\n",
        "          smooth_pressure=False\n",
        "      )\n",
        "    else:\n",
        "      plot_msl_with_10mwind(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          wind_units=wind_units,\n",
        "          thin_factor=thin_factor,\n",
        "          n_contours=20,\n",
        "          plot_cities=True,\n",
        "          pop_filter=500,\n",
        "          smooth_pressure=True\n",
        "      )\n",
        "elif wxvar == \"850mb_Temps\":\n",
        "    #getting MSL\n",
        "    path1 = download_ecmwf_ens(\n",
        "        param=['gh', 't'],\n",
        "        init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "        steps=list(range(tr[0]-6, tr[1], 6)),\n",
        "        level_type=\"pl\",\n",
        "        levels=[850],\n",
        "        members=[representatives[int(cluster)]],\n",
        "        target_dir=\".\",\n",
        "        source=\"aws\"\n",
        "    )\n",
        "\n",
        "    # 1) Load\n",
        "    ds = xr.open_dataset(\n",
        "        path1,\n",
        "        engine=\"cfgrib\"\n",
        "    )\n",
        "    # ds is your Dataset with coords and variables: step, latitude, longitude, msl, tp\n",
        "    if zoom_area == \"Full_Extent\":\n",
        "      plot_upper_level_temps(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          level=850,\n",
        "          n_contours=20\n",
        "      )\n",
        "    else:\n",
        "      plot_upper_level_temps(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          level=850,\n",
        "          n_contours=20,\n",
        "          pop_filter=500,\n",
        "          plot_cities=True\n",
        "      )\n",
        "\n",
        "elif wxvar == \"925mb_Temps\":\n",
        "    #getting MSL\n",
        "    path1 = download_ecmwf_ens(\n",
        "        param=['gh', 't'],\n",
        "        init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "        steps=list(range(tr[0]-6, tr[1], 6)),\n",
        "        level_type=\"pl\",\n",
        "        levels=[925],\n",
        "        members=[representatives[int(cluster)]],\n",
        "        target_dir=\".\",\n",
        "        source=\"aws\"\n",
        "    )\n",
        "\n",
        "    # 1) Load\n",
        "    ds = xr.open_dataset(\n",
        "        path1,\n",
        "        engine=\"cfgrib\"\n",
        "    )\n",
        "    # ds is your Dataset with coords and variables: step, latitude, longitude, msl, tp\n",
        "    if zoom_area == \"Full_Extent\":\n",
        "      plot_upper_level_temps(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          level=925,\n",
        "          n_contours=20\n",
        "      )\n",
        "    else:\n",
        "      plot_upper_level_temps(\n",
        "          ds,\n",
        "          lat_min=zoom_area_dict[zoom_area][0], lat_max=zoom_area_dict[zoom_area][1],\n",
        "          lon_min=zoom_area_dict[zoom_area][2], lon_max=zoom_area_dict[zoom_area][3],\n",
        "          level=925,\n",
        "          n_contours=20,\n",
        "          plot_cities=True,\n",
        "          pop_filter=500\n",
        "      )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LTLifyDDV9yb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k6DRBRAXCyNh",
        "pNRHFuNmC-2K"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d9efab89797b4f7e4129f7fe7c375038c6a3f1b6c83da7efdea02c4da588d5be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}